{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "53d6b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample = 3000\n",
    "num_burn = 1000\n",
    "sample_size = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "09f393f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [00:09<00:00, 428.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.10381641187036209, 0.18301499999999998)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dgp import sample_network_chain, get_graph, sample_Y1, sample_Y2, agcEffect\n",
    "import numpy as np\n",
    "\n",
    "# 1. Simulate or load data\n",
    "min_degree = 1\n",
    "max_degree = 2\n",
    "adj = get_graph(sample_size, min_degree, max_degree, seed=1)\n",
    "\n",
    "tau = np.array([-1.0, 0.50, -0.50])       # shape (3,)\n",
    "rho = np.array([[0,0.1,0.2],\n",
    "                [0.1,0,0.1],\n",
    "                [0.2,0.1,0]])      # shape (3, 3), with 0s on the diagonal\n",
    "nu = np.array([0.1,0,0,0.1,0,0,0.1,0,0]).reshape(3,3)       # shape (3, 3)\n",
    "gamma = np.array([-2.00,0.50,-0.05,0.20,0.05,0.25,-0.08,0.30])     # shape (8,)\n",
    "beta = np.array([-0.30,-0.60,-0.60,-0.20,-0.05,-0.10,-0.01,0.40,0.01,0.20])     # shape (10,)\n",
    "\n",
    "Y_chain, A_chain, L_chain = sample_network_chain(adj, tau, rho, nu, gamma, beta, R=num_sample,\n",
    "    burnin_R=num_burn, seed=0, sample_Y_func=sample_Y2, Atype=('gen', 0.7))\n",
    "\n",
    "Y_chain = Y_chain[::3]\n",
    "A_chain = A_chain[::3]\n",
    "L_chain = L_chain[::3]\n",
    "\n",
    "dir, dir2 = [], []\n",
    "for i in range(Y_chain.shape[0]):\n",
    "    Y = Y_chain[i]\n",
    "    A = A_chain[i]\n",
    "    L = L_chain[i]\n",
    "    dir.append(np.mean(Y[A==1]) - np.mean(Y[A==0]))\n",
    "    dir2.append(np.mean(A))\n",
    "\n",
    "np.mean(dir), np.mean(dir2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4f45cf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "def compute_avg_effects_std_from_raw(psi_vec, adj_matrix, h=2):\n",
    "    N = len(psi_vec)\n",
    "    avg_effects = np.mean(psi_vec)\n",
    "    \n",
    "    # Centered residuals\n",
    "    g = psi_vec - avg_effects\n",
    "    \n",
    "    # Build graph and compute pairwise distances\n",
    "    G = nx.from_numpy_array(adj_matrix)\n",
    "    dist = dict(nx.all_pairs_shortest_path_length(G, cutoff=h))\n",
    "    \n",
    "    # Network HAC estimator\n",
    "    hac_var = 0.0\n",
    "    for i in range(N):\n",
    "        for j, dij in dist[i].items():\n",
    "            weight = max(1 - dij / h, 0)  # Bartlett kernel\n",
    "            hac_var += weight * g[i] * g[j]\n",
    "    \n",
    "    hac_var /= N\n",
    "    se_hac = np.sqrt(hac_var)/np.sqrt(N)\n",
    "\n",
    "    return avg_effects, se_hac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "986cbfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21455443157812562 0.21466869218749998 0.21911559875000003\n"
     ]
    }
   ],
   "source": [
    "var = []\n",
    "var_sim = []\n",
    "est = []\n",
    "idx = 1\n",
    "for i in range(Y_chain.shape[0]):\n",
    "    avg_effects, se_hac = compute_avg_effects_std_from_raw(L_chain[i,:,0],adj,h=3)\n",
    "    var.append(se_hac**2*sample_size)\n",
    "    var_sim.append(np.var(L_chain[i,:,0]))\n",
    "    est.append(avg_effects)\n",
    "\n",
    "var_true = np.var(est)\n",
    "print(np.mean(var), np.mean(var_sim), var_true*sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9232d7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50 53]\n",
      "-0.03403931011672873\n",
      "0.02977360699638314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0012715037690732291"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 51\n",
    "print(np.where(adj[k])[0])\n",
    "for j in np.where(adj[k])[0]:\n",
    "    print(np.corrcoef(L_chain[:,k,0], L_chain[:,j,0])[0,1])\n",
    "\n",
    "ic = []\n",
    "for j in np.where(adj[0]==0)[0]:\n",
    "    ic.append(np.corrcoef(L_chain[:,k,0], L_chain[:,j,0])[0,1])\n",
    "np.mean(ic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6bb446f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 800, 3), (1000, 800))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_chain.shape, Y_chain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbc8802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ljz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
